
decl function &__sin(arg_f32 %ret)(arg_f32 %in);

decl function &__cos(arg_f32 %ret)(arg_f32 %in);

decl function &__exp(arg_f32 %ret)(arg_f32 %in);


function &__sin(arg_f32 %__sin)(arg_f32 %in)
{

@__sin_entry:
	// BB#0:
	ld_arg_align(4)_f32	$s0, [%in];
	mov_b32	$s2, $s0;
	and_b32	$s1, $s2, 2147483647;
	mov_b32	$s4, $s1;
	cmp_geu_ftz_b1_f32	$c0, $s4, 0F4b000000;
	cbr_b1	$c0, @BB0_2;
	// BB#1:
	nfma_f32	$s3, $s4, 0F3f22f983, 0F3f000000;
	trunc_ftz_f32	$s5, $s3;
	mul_ftz_f32	$s6, $s5, 0Fbfc90fda;
	fma_ftz_f32	$s6, $s5, 0F3fc90fda, $s6;
	mul_ftz_f32	$s8, $s5, 0F3fc90fda;
	sub_ftz_f32	$s7, $s4, $s8;
	sub_ftz_f32	$s4, $s4, $s7;
	sub_ftz_f32	$s4, $s4, $s8;
	sub_ftz_f32	$s4, $s4, $s6;
	add_ftz_f32	$s6, $s7, $s4;
	mul_ftz_f32	$s4, $s5, 0Fa7c234c4;
	mul_ftz_f32	$s8, $s5, 0F33a22168;
	sub_ftz_f32	$s7, $s6, $s8;
	fma_ftz_f32	$s4, $s5, 0F27c234c4, $s4;
	mul_ftz_f32	$s9, $s5, 0Fb3a22168;
	neg_f32	$s4, $s4;
	fma_ftz_f32	$s9, $s5, 0F33a22168, $s9;
	cvt_ftz_s32_f32	$s3, $s3;
	mul_ftz_f32	$s5, $s5, 0F27c234c4;
	sub_ftz_f32	$s6, $s6, $s7;
	sub_ftz_f32	$s6, $s6, $s8;
	sub_ftz_f32	$s6, $s6, $s9;
	add_ftz_f32	$s7, $s7, $s6;
	sub_ftz_f32	$s6, $s7, $s5;
	sub_ftz_f32	$s7, $s7, $s6;
	sub_ftz_f32	$s5, $s7, $s5;
	add_ftz_f32	$s5, $s6, $s5;
	br	@BB0_3;

@BB0_2:
	and_b32	$s3, $s2, 8388607;
	or_b32	$s5, $s3, 8388608;
	mulhi_u32	$s4, $s5, 4266746795;
	mad_u32	$s3, $s5, 1011060801, $s4;
	cmp_lt_b1_u32	$c0, $s3, $s4;
	cvt_u32_b1	$s4, $c0;
	mulhi_u32	$s6, $s5, 1011060801;
	add_u32	$s6, $s4, $s6;
	mad_u32	$s4, $s5, 3680671129, $s6;
	cmp_lt_b1_u32	$c0, $s4, $s6;
	cvt_u32_b1	$s6, $c0;
	mulhi_u32	$s7, $s5, 3680671129;
	add_u32	$s7, $s6, $s7;
	mad_u32	$s6, $s5, 4113882560, $s7;
	cmp_lt_b1_u32	$c0, $s6, $s7;
	cvt_u32_b1	$s7, $c0;
	mulhi_u32	$s8, $s5, 4113882560;
	add_u32	$s8, $s7, $s8;
	mad_u32	$s7, $s5, 4230436817, $s8;
	cmp_lt_b1_u32	$c0, $s7, $s8;
	cvt_u32_b1	$s8, $c0;
	mulhi_u32	$s9, $s5, 4230436817;
	add_u32	$s9, $s8, $s9;
	mad_u32	$s8, $s5, 1313084713, $s9;
	cmp_lt_b1_u32	$c0, $s8, $s9;
	cvt_u32_b1	$s9, $c0;
	mulhi_u32	$s10, $s5, 1313084713;
	add_u32	$s10, $s9, $s10;
	mad_u32	$s9, $s5, 2734261102, $s10;
	cmp_lt_b1_u32	$c0, $s9, $s10;
	cvt_u32_b1	$s12, $c0;
	mulhi_u32	$s13, $s5, 2734261102;
	mul_u32	$s11, $s5, 4266746795;
	shr_u32	$s5, $s1, 23;
	add_u32	$s10, $s5, 4294967176;
	cmp_gt_b1_u32	$c0, $s10, 31;
	cmov_b32	$s5, $c0, $s3, $s4;
	cmov_b32	$s11, $c0, $s11, $s3;
	cvt_u32_b1	$s14, $c0;
	cmov_b32	$s3, $c0, $s7, $s8;
	cmov_b32	$s7, $c0, $s6, $s7;
	cmov_b32	$s4, $c0, $s4, $s6;
	add_u32	$s6, $s12, $s13;
	cmov_b32	$s6, $c0, $s9, $s6;
	cmov_b32	$s9, $c0, $s8, $s9;
	neg_s32	$s8, $s14;
	and_b32	$s8, $s8, 32;
	sub_u32	$s10, $s10, $s8;
	cmp_gt_b1_u32	$c0, $s10, 31;
	cmov_b32	$s8, $c0, $s5, $s4;
	cmov_b32	$s11, $c0, $s11, $s5;
	cvt_u32_b1	$s12, $c0;
	cmov_b32	$s5, $c0, $s3, $s9;
	cmov_b32	$s3, $c0, $s7, $s3;
	cmov_b32	$s4, $c0, $s4, $s7;
	cmov_b32	$s9, $c0, $s9, $s6;
	neg_s32	$s6, $s12;
	and_b32	$s6, $s6, 32;
	sub_u32	$s6, $s10, $s6;
	cmp_gt_b1_u32	$c0, $s6, 31;
	cmov_b32	$s7, $c0, $s8, $s4;
	cmov_b32	$s8, $c0, $s11, $s8;
	cvt_u32_b1	$s12, $c0;
	cmov_b32	$s9, $c0, $s5, $s9;
	cmov_b32	$s10, $c0, $s3, $s5;
	cmov_b32	$s11, $c0, $s4, $s3;
	neg_s32	$s3, $s12;
	and_b32	$s3, $s3, 32;
	sub_u32	$s6, $s6, $s3;
	cmp_gt_b1_u32	$c0, $s6, 31;
	cmov_b32	$s3, $c0, $s7, $s11;
	cmov_b32	$s5, $c0, $s8, $s7;
	cvt_u32_b1	$s7, $c0;
	cmov_b32	$s4, $c0, $s10, $s9;
	cmov_b32	$s8, $c0, $s11, $s10;
	neg_s32	$s7, $s7;
	and_b32	$s7, $s7, 32;
	sub_u32	$s9, $s7, $s6;
	shr_u32	$s10, $s5, $s9;
	shr_u32	$s12, $s3, $s9;
	neg_s32	$s11, $s9;
	shl_u32	$s13, $s8, $s11;
	or_b32	$s12, $s13, $s12;
	shl_u32	$s13, $s3, $s11;
	cmp_ne_b1_s32	$c0, $s6, $s7;
	cmov_b32	$s7, $c0, $s12, $s8;
	or_b32	$s6, $s13, $s10;
	shl_u32	$s10, $s4, $s11;
	shr_u32	$s8, $s8, $s9;
	or_b32	$s8, $s10, $s8;
	cmov_b32	$s9, $c0, $s6, $s3;
	cmov_b32	$s3, $c0, $s8, $s4;
	shl_u32	$s4, $s3, 2;
	shr_u32	$s6, $s7, 30;
	or_b32	$s6, $s4, $s6;
	shr_u32	$s4, $s3, 29;
	shl_u32	$s4, $s4, 31;
	shr_s32	$s10, $s4, 31;
	xor_b32	$s8, $s10, $s6;
	firstbit_u32_u32	$s11, $s8;
	cmp_eq_b1_s32	$c0, $s10, $s6;
	cmov_b32	$s6, $c0, 32, $s11;
	shr_u32	$s5, $s5, 30;
	shr_u32	$s11, $s9, 30;
	shl_u32	$s7, $s7, 2;
	or_b32	$s7, $s7, $s11;
	shl_u32	$s9, $s9, 2;
	or_b32	$s9, $s9, $s5;
	sub_u32	$s5, 31, $s6;
	xor_b32	$s9, $s10, $s9;
	shr_u32	$s11, $s9, $s5;
	neg_s32	$s9, $s5;
	xor_b32	$s12, $s10, $s7;
	shl_u32	$s7, $s12, $s9;
	or_b32	$s7, $s7, $s11;
	shr_u32	$s10, $s7, 9;
	shr_u32	$s5, $s12, $s5;
	shl_u32	$s8, $s8, $s9;
	or_b32	$s5, $s8, $s5;
	shl_u32	$s8, $s5, 23;
	or_b32	$s8, $s8, $s10;
	firstbit_u32_u32	$s9, $s8;
	cmp_eq_b1_s32	$c0, $s8, 0;
	cmov_b32	$s9, $c0, 32, $s9;
	sub_u32	$s10, 126, $s6;
	shr_u32	$s11, $s3, 30;
	bitextract_u32	$s3, $s3, 29, 1;
	shl_u32	$s10, $s10, 23;
	add_u32	$s3, $s3, $s11;
	or_b32	$s10, $s10, $s4;
	sub_u32	$s6, 102, $s6;
	sub_u32	$s11, 31, $s9;
	shr_u32	$s7, $s7, $s11;
	neg_s32	$s11, $s11;
	shl_u32	$s8, $s8, $s11;
	or_b32	$s7, $s8, $s7;
	shr_u32	$s7, $s7, 9;
	sub_u32	$s6, $s6, $s9;
	shl_u32	$s6, $s6, 23;
	or_b32	$s4, $s6, $s4;
	shr_u32	$s5, $s5, 9;
	or_b32	$s5, $s10, $s5;
	or_b32	$s6, $s4, $s7;
	mul_ftz_f32	$s4, $s5, 0F3fc90fda;
	mul_ftz_f32	$s7, $s5, 0Fbfc90fda;
	fma_ftz_f32	$s7, $s5, 0F3fc90fda, $s7;
	fma_ftz_f32	$s5, $s5, 0F33a22168, $s7;
	fma_ftz_f32	$s6, $s6, 0F3fc90fda, $s5;
	add_ftz_f32	$s5, $s6, $s4;
	sub_ftz_f32	$s4, $s5, $s4;
	sub_ftz_f32	$s4, $s6, $s4;

@BB0_3:
	// %_Z3sinf.exit
	mov_b32	$s6, $s5;
	and_b32	$s6, $s6, 2147483647;
	add_u32	$s7, $s6, 4278190080;
	add_u32	$s8, $s6, 3244713574;
	cmp_lt_b1_u32	$c0, $s8, 11429479;
	cmov_b32	$s7, $c0, $s7, 0;
	cmp_gt_b1_u32	$c0, $s6, 1061683200;
	cmov_b32	$s7, $c0, 1049624576, $s7;
	and_b32	$s6, $s3, 2;
	cmp_gt_b1_u32	$c0, $s6, 1;
	cvt_u32_b1	$s6, $c0;
	mul_ftz_f32	$s8, $s5, $s5;
	nfma_f32	$s9, $s8, 0F2f2ec9d3, 0Fb2d72f34;
	nfma_f32	$s9, $s8, $s9, 0F3636df25;
	nfma_f32	$s9, $s8, $s9, 0Fb95009d4;
	nfma_f32	$s10, $s8, $s9, 0F3c088887;
	mul_ftz_f32	$s9, $s5, $s8;
	neg_f32	$s11, $s9;
	mul_ftz_f32	$s10, $s10, $s11;
	nfma_f32	$s11, $s8, 0Fad47d74e, 0F310f74f6;
	nfma_f32	$s11, $s8, $s11, 0Fb492923a;
	nfma_f32	$s11, $s8, $s11, 0F37d00ae2;
	nfma_f32	$s10, $s4, 0F3f000000, $s10;
	nfma_f32	$s12, $s8, $s11, 0Fbab60b60;
	neg_f32	$s11, $s5;
	mul_ftz_f32	$s11, $s4, $s11;
	nfma_f32	$s12, $s8, $s12, 0F3d2aaaab;
	mul_ftz_f32	$s12, $s8, $s12;
	neg_f32	$s4, $s4;
	and_b32	$s3, $s3, 1;
	nfma_f32	$s4, $s8, $s10, $s4;
	nfma_f32	$s4, $s9, 0F3e2aaaab, $s4;
	sub_ftz_f32	$s4, $s5, $s4;
	nfma_f32	$s5, $s8, $s12, $s11;
	neg_f32	$s9, $s7;
	nfma_f32	$s8, $s8, 0F3f000000, $s9;
	sub_ftz_f32	$s5, $s8, $s5;
	sub_ftz_f32	$s7, 0F3f800000, $s7;
	sub_ftz_f32	$s5, $s7, $s5;
	cvt_b1_u32	$c0, $s3;
	cmov_b32	$s3, $c0, $s5, $s4;
	xor_b32	$s2, $s1, $s2;
	shl_u32	$s4, $s6, 31;
	xor_b32	$s2, $s2, $s4;
	xor_b32	$s2, $s2, $s3;
	cmp_gt_b1_u32	$c0, $s1, 2139095039;
	cmov_b32	$s1, $c0, 2143289344, $s2;
	cmp_eq_ftz_b1_f32	$c0, $s0, 0F00000000;
	cmov_b32	$s0, $c0, $s0, $s1;
	st_arg_align(4)_f32	$s0, [%__sin];
	ret;
};

function &__cos(arg_f32 %__cos)(arg_f32 %in)
{

@__cos_entry:
	// BB#0:
	ld_arg_align(4)_f32	$s0, [%in];
	mov_b32	$s1, $s0;
	and_b32	$s0, $s1, 2147483647;
	mov_b32	$s2, $s0;
	cmp_geu_ftz_b1_f32	$c0, $s2, 0F4b000000;
	cbr_b1	$c0, @BB1_2;
	// BB#1:
	nfma_f32	$s1, $s2, 0F3f22f983, 0F3f000000;
	trunc_ftz_f32	$s3, $s1;
	mul_ftz_f32	$s4, $s3, 0Fbfc90fda;
	fma_ftz_f32	$s4, $s3, 0F3fc90fda, $s4;
	mul_ftz_f32	$s6, $s3, 0F3fc90fda;
	sub_ftz_f32	$s5, $s2, $s6;
	sub_ftz_f32	$s2, $s2, $s5;
	sub_ftz_f32	$s2, $s2, $s6;
	sub_ftz_f32	$s2, $s2, $s4;
	add_ftz_f32	$s4, $s5, $s2;
	mul_ftz_f32	$s2, $s3, 0Fa7c234c4;
	mul_ftz_f32	$s6, $s3, 0F33a22168;
	sub_ftz_f32	$s5, $s4, $s6;
	fma_ftz_f32	$s2, $s3, 0F27c234c4, $s2;
	mul_ftz_f32	$s7, $s3, 0Fb3a22168;
	neg_f32	$s2, $s2;
	fma_ftz_f32	$s7, $s3, 0F33a22168, $s7;
	cvt_ftz_s32_f32	$s1, $s1;
	mul_ftz_f32	$s3, $s3, 0F27c234c4;
	sub_ftz_f32	$s4, $s4, $s5;
	sub_ftz_f32	$s4, $s4, $s6;
	sub_ftz_f32	$s4, $s4, $s7;
	add_ftz_f32	$s5, $s5, $s4;
	sub_ftz_f32	$s4, $s5, $s3;
	sub_ftz_f32	$s5, $s5, $s4;
	sub_ftz_f32	$s3, $s5, $s3;
	add_ftz_f32	$s3, $s4, $s3;
	br	@BB1_3;

@BB1_2:
	and_b32	$s1, $s1, 8388607;
	or_b32	$s3, $s1, 8388608;
	mulhi_u32	$s2, $s3, 4266746795;
	mad_u32	$s1, $s3, 1011060801, $s2;
	cmp_lt_b1_u32	$c0, $s1, $s2;
	cvt_u32_b1	$s2, $c0;
	mulhi_u32	$s4, $s3, 1011060801;
	add_u32	$s4, $s2, $s4;
	mad_u32	$s2, $s3, 3680671129, $s4;
	cmp_lt_b1_u32	$c0, $s2, $s4;
	cvt_u32_b1	$s4, $c0;
	mulhi_u32	$s5, $s3, 3680671129;
	add_u32	$s5, $s4, $s5;
	mad_u32	$s4, $s3, 4113882560, $s5;
	cmp_lt_b1_u32	$c0, $s4, $s5;
	cvt_u32_b1	$s5, $c0;
	mulhi_u32	$s6, $s3, 4113882560;
	add_u32	$s6, $s5, $s6;
	mad_u32	$s5, $s3, 4230436817, $s6;
	cmp_lt_b1_u32	$c0, $s5, $s6;
	cvt_u32_b1	$s6, $c0;
	mulhi_u32	$s7, $s3, 4230436817;
	add_u32	$s7, $s6, $s7;
	mad_u32	$s6, $s3, 1313084713, $s7;
	cmp_lt_b1_u32	$c0, $s6, $s7;
	cvt_u32_b1	$s7, $c0;
	mulhi_u32	$s8, $s3, 1313084713;
	add_u32	$s8, $s7, $s8;
	mad_u32	$s7, $s3, 2734261102, $s8;
	cmp_lt_b1_u32	$c0, $s7, $s8;
	cvt_u32_b1	$s10, $c0;
	mulhi_u32	$s11, $s3, 2734261102;
	mul_u32	$s9, $s3, 4266746795;
	shr_u32	$s3, $s0, 23;
	add_u32	$s8, $s3, 4294967176;
	cmp_gt_b1_u32	$c0, $s8, 31;
	cmov_b32	$s3, $c0, $s1, $s2;
	cmov_b32	$s9, $c0, $s9, $s1;
	cvt_u32_b1	$s12, $c0;
	cmov_b32	$s1, $c0, $s5, $s6;
	cmov_b32	$s5, $c0, $s4, $s5;
	cmov_b32	$s2, $c0, $s2, $s4;
	add_u32	$s4, $s10, $s11;
	cmov_b32	$s4, $c0, $s7, $s4;
	cmov_b32	$s7, $c0, $s6, $s7;
	neg_s32	$s6, $s12;
	and_b32	$s6, $s6, 32;
	sub_u32	$s8, $s8, $s6;
	cmp_gt_b1_u32	$c0, $s8, 31;
	cmov_b32	$s6, $c0, $s3, $s2;
	cmov_b32	$s9, $c0, $s9, $s3;
	cvt_u32_b1	$s10, $c0;
	cmov_b32	$s3, $c0, $s1, $s7;
	cmov_b32	$s1, $c0, $s5, $s1;
	cmov_b32	$s2, $c0, $s2, $s5;
	cmov_b32	$s7, $c0, $s7, $s4;
	neg_s32	$s4, $s10;
	and_b32	$s4, $s4, 32;
	sub_u32	$s4, $s8, $s4;
	cmp_gt_b1_u32	$c0, $s4, 31;
	cmov_b32	$s5, $c0, $s6, $s2;
	cmov_b32	$s6, $c0, $s9, $s6;
	cvt_u32_b1	$s10, $c0;
	cmov_b32	$s7, $c0, $s3, $s7;
	cmov_b32	$s8, $c0, $s1, $s3;
	cmov_b32	$s9, $c0, $s2, $s1;
	neg_s32	$s1, $s10;
	and_b32	$s1, $s1, 32;
	sub_u32	$s4, $s4, $s1;
	cmp_gt_b1_u32	$c0, $s4, 31;
	cmov_b32	$s1, $c0, $s5, $s9;
	cmov_b32	$s3, $c0, $s6, $s5;
	cvt_u32_b1	$s5, $c0;
	cmov_b32	$s2, $c0, $s8, $s7;
	cmov_b32	$s6, $c0, $s9, $s8;
	neg_s32	$s5, $s5;
	and_b32	$s5, $s5, 32;
	sub_u32	$s7, $s5, $s4;
	shr_u32	$s8, $s3, $s7;
	shr_u32	$s10, $s1, $s7;
	neg_s32	$s9, $s7;
	shl_u32	$s11, $s6, $s9;
	or_b32	$s10, $s11, $s10;
	shl_u32	$s11, $s1, $s9;
	cmp_ne_b1_s32	$c0, $s4, $s5;
	cmov_b32	$s5, $c0, $s10, $s6;
	or_b32	$s4, $s11, $s8;
	shl_u32	$s8, $s2, $s9;
	shr_u32	$s6, $s6, $s7;
	or_b32	$s6, $s8, $s6;
	cmov_b32	$s7, $c0, $s4, $s1;
	cmov_b32	$s1, $c0, $s6, $s2;
	shl_u32	$s2, $s1, 2;
	shr_u32	$s4, $s5, 30;
	or_b32	$s4, $s2, $s4;
	shr_u32	$s2, $s1, 29;
	shl_u32	$s2, $s2, 31;
	shr_s32	$s8, $s2, 31;
	xor_b32	$s6, $s8, $s4;
	firstbit_u32_u32	$s9, $s6;
	cmp_eq_b1_s32	$c0, $s8, $s4;
	cmov_b32	$s4, $c0, 32, $s9;
	shr_u32	$s3, $s3, 30;
	shr_u32	$s9, $s7, 30;
	shl_u32	$s5, $s5, 2;
	or_b32	$s5, $s5, $s9;
	shl_u32	$s7, $s7, 2;
	or_b32	$s7, $s7, $s3;
	sub_u32	$s3, 31, $s4;
	xor_b32	$s7, $s8, $s7;
	shr_u32	$s9, $s7, $s3;
	neg_s32	$s7, $s3;
	xor_b32	$s10, $s8, $s5;
	shl_u32	$s5, $s10, $s7;
	or_b32	$s5, $s5, $s9;
	shr_u32	$s8, $s5, 9;
	shr_u32	$s3, $s10, $s3;
	shl_u32	$s6, $s6, $s7;
	or_b32	$s3, $s6, $s3;
	shl_u32	$s6, $s3, 23;
	or_b32	$s6, $s6, $s8;
	firstbit_u32_u32	$s7, $s6;
	cmp_eq_b1_s32	$c0, $s6, 0;
	cmov_b32	$s7, $c0, 32, $s7;
	sub_u32	$s8, 126, $s4;
	shr_u32	$s9, $s1, 30;
	bitextract_u32	$s1, $s1, 29, 1;
	shl_u32	$s8, $s8, 23;
	add_u32	$s1, $s1, $s9;
	or_b32	$s8, $s8, $s2;
	sub_u32	$s4, 102, $s4;
	sub_u32	$s9, 31, $s7;
	shr_u32	$s5, $s5, $s9;
	neg_s32	$s9, $s9;
	shl_u32	$s6, $s6, $s9;
	or_b32	$s5, $s6, $s5;
	shr_u32	$s5, $s5, 9;
	sub_u32	$s4, $s4, $s7;
	shl_u32	$s4, $s4, 23;
	or_b32	$s2, $s4, $s2;
	shr_u32	$s3, $s3, 9;
	or_b32	$s3, $s8, $s3;
	or_b32	$s4, $s2, $s5;
	mul_ftz_f32	$s2, $s3, 0F3fc90fda;
	mul_ftz_f32	$s5, $s3, 0Fbfc90fda;
	fma_ftz_f32	$s5, $s3, 0F3fc90fda, $s5;
	fma_ftz_f32	$s3, $s3, 0F33a22168, $s5;
	fma_ftz_f32	$s4, $s4, 0F3fc90fda, $s3;
	add_ftz_f32	$s3, $s4, $s2;
	sub_ftz_f32	$s2, $s3, $s2;
	sub_ftz_f32	$s2, $s4, $s2;

@BB1_3:
	// %_Z3cosf.exit
	mov_b32	$s4, $s3;
	and_b32	$s4, $s4, 2147483647;
	add_u32	$s5, $s4, 4278190080;
	add_u32	$s6, $s4, 3244713574;
	cmp_lt_b1_u32	$c0, $s6, 11429479;
	cmov_b32	$s5, $c0, $s5, 0;
	cmp_gt_b1_u32	$c0, $s4, 1061683200;
	cmov_b32	$s6, $c0, 1049624576, $s5;
	and_b32	$s4, $s1, 2;
	cmp_gt_b1_u32	$c0, $s4, 1;
	cvt_u32_b1	$s4, $c0;
	mul_ftz_f32	$s5, $s3, $s3;
	nfma_f32	$s7, $s5, 0F2f2ec9d3, 0Fb2d72f34;
	nfma_f32	$s7, $s5, $s7, 0F3636df25;
	nfma_f32	$s7, $s5, $s7, 0Fb95009d4;
	nfma_f32	$s8, $s5, $s7, 0F3c088887;
	mul_ftz_f32	$s7, $s3, $s5;
	neg_f32	$s9, $s7;
	neg_f32	$s10, $s3;
	mul_ftz_f32	$s8, $s8, $s9;
	sub_ftz_f32	$s9, 0F3f800000, $s6;
	mul_ftz_f32	$s10, $s2, $s10;
	nfma_f32	$s11, $s5, 0Fad47d74e, 0F310f74f6;
	nfma_f32	$s11, $s5, $s11, 0Fb492923a;
	nfma_f32	$s11, $s5, $s11, 0F37d00ae2;
	nfma_f32	$s11, $s5, $s11, 0Fbab60b60;
	nfma_f32	$s11, $s5, $s11, 0F3d2aaaab;
	mul_ftz_f32	$s11, $s5, $s11;
	and_b32	$s1, $s1, 1;
	nfma_f32	$s10, $s5, $s11, $s10;
	neg_f32	$s6, $s6;
	nfma_f32	$s6, $s5, 0F3f000000, $s6;
	sub_ftz_f32	$s6, $s6, $s10;
	sub_ftz_f32	$s6, $s9, $s6;
	nfma_f32	$s8, $s2, 0F3f000000, $s8;
	neg_f32	$s2, $s2;
	nfma_f32	$s2, $s5, $s8, $s2;
	nfma_f32	$s2, $s7, 0F3e2aaaab, $s2;
	sub_ftz_f32	$s2, $s3, $s2;
	neg_f32	$s2, $s2;
	cvt_b1_u32	$c0, $s1;
	cmov_b32	$s1, $c0, $s2, $s6;
	shl_u32	$s2, $s4, 31;
	xor_b32	$s1, $s1, $s2;
	cmp_gt_b1_u32	$c0, $s0, 2139095039;
	cmov_b32	$s0, $c0, 2143289344, $s1;
	st_arg_align(4)_f32	$s0, [%__cos];
	ret;
};

function &__exp(arg_f32 %__exp)(arg_f32 %in)
{

@__exp_entry:
	// BB#0:
	ld_arg_align(4)_f32	$s0, [%in];
	mov_b32	$s1, $s0;
	and_b32	$s1, $s1, 4294963200;
	sub_ftz_f32	$s2, $s0, $s1;
	mul_ftz_f32	$s3, $s2, 0F39a3b295;
	nfma_f32	$s2, $s2, 0F3fb8a000, $s3;
	nfma_f32	$s2, $s1, 0F39a3b295, $s2;
	nexp2_f32	$s2, $s2;
	mul_ftz_f32	$s1, $s1, 0F3fb8a000;
	nexp2_f32	$s1, $s1;
	mul_ftz_f32	$s1, $s2, $s1;
	cmp_lt_ftz_b1_f32	$c0, $s0, 0Fc2aeac50;
	cmov_b32	$s1, $c0, 0, $s1;
	cmp_gt_ftz_b1_f32	$c0, $s0, 0F42b17218;
	cmov_b32	$s0, $c0, 2139095040, $s1;
	st_arg_align(4)_f32	$s0, [%__exp];
	ret;
};

